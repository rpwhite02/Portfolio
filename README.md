# Ronan White

# [Project 1: Data Visualizations and Predictions](https://github.com/rpwhite02/Portfolio/tree/main/Project1)
* Use python libraries pandas, matplotlib, seaborn, and scikit-learn.
* Created lineplots and barplots using matplotlib and seaborn, as well as a decision tree regression model using scikit-learn.
* Based on a dataset from the National Center for Education Statistics called "Percentage of persons 25 to 29 years old with
selected levels of educational attainment, by race/ethnicity and sex: Selected years, 1920 through 2018."
* Answered questions regarding the types of degrees that percentages of people of different races and genders acquire and predicted
degree types using a decision tree regression model.

![](/images/lineplot.png)
<figcaption align = "center">
<b> Plot showing percentage of all people obtaining minimum of Bachelor's degree over time</b>
</figcaption>


![](/images/hispanicplot.png)
<figcaption align = "center">
<b>Plot of two bars next to each other comparing the minimum degrees Hispanic people obtain</b>
</figcaption>


# [Project 2: Python Search Engine](https://github.com/rpwhite02/Portfolio/tree/main/Project2)
* Assignment from my Data Programming class which utilized classes and objects in Python.
* Code to setup a server to host the search engine was given to the class, as well as HTML and CSS
code that set up the presentation and functionality of the search engine website.
* The document file contains the document class which represents all the data and words in a
single web page (document) and computes the term frequency for a given term in a document.
* The search engine file contains the search engine class which represents a directory of document
objects and computes the TFIDF (term frequency-inverse document frequency) score for a given
search query in each document object. In other words, this class computes how important a word
in a search query is to what the user is searching for.
* The included python code for this project is just to look through web pages and scan them for all words, as
well as calculate the importance of a word in a search query and present web pages (documents) that
correlate with the search query. Code to set up the server and website isn't included.

![](/images/searchbar.png)
<figcaption align = "center">
<b>The search bar before entering search query</b>
</figcaption>


![](/images/searchresults.png)
<figcaption align = "center">
<b>Suggested results after typing "computer" into the search bar</b>
</figcaption>


# [Project 3: Mapping using Geopandas](https://github.com/rpwhite02/Portfolio/blob/main/Project%203/code.py)
* Used 2 different datasets, one was a shapefile in order to map the shapes of the countie and census tracts and
the other file had data regarding each census tracts food access data.
* Used Geopandas library in python to map census tracts and counties in Washington state.
* Showed which census tracts have access to food source within 0.5 miles (urban) and 10 miles (rural).
* Calculated which census tracts we have food access data for in a percentage.
# Displayed data processing skills using pandas and created visualizations based on filtered/processed data

![](/images/censustractmap.png)
<figcaption align = "center">
<b>Map of census tracts in Washington state</b>
</figcaption>


![](/images/censustractpopulations.png)
<figcaption align = "center">
<b>We're missing data for some census tracts</b>
</figcaption>
